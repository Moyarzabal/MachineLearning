# -*- coding: utf-8 -*-
"""ADA4-digit.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Eaw-jflWlGEPyMIRDs3Y3FNuXBejjI4f
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from scipy.io import loadmat

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive # driveを接続
drive.mount('/content/gdrive')

# %cd /content/gdrive/My Drive/SML/

data = loadmat('digit.mat')
train = data['X']
test = data['T']

t = test[:, :, 1]

mu1 = np.mean(train[:, :, 0], axis=1)
mu2 = np.mean(train[:, :, 1], axis=1)
S = (np.cov(train[:, :, 0]) + np.cov(train[:, :, 1])) / 2
p1 = mu1[None, :].dot(invS).dot(t) - mu1[None, :].dot(invS).dot(mu1[:, None]) / 2
p2 = mu2[None, :].dot(invS).dot(t) - mu2[None, :].dot(invS).dot(mu2[:, None]) / 2
result = np.sign(p1 - p2)

import numpy as np;
#import matplotlib; matplotlib.use('TkAgg') 
import matplotlib.pyplot as plt; np.random.seed(0)  # set seed for reproducibility 


def calc_design_matrix(x, c, h):     
  return np.exp(-(x[None] - c[:, None]) ** 2 / (2 * h ** 2)) 


# calculate design matrix 
h = 0.1 
k = calc_design_matrix(x, x, h) 
# solve the least square problem 
theta = np.linalg.inv(np.dot(k.T, k) + 0.000001 * np.identity(256)) @ k.T @ test[:, None]
prediction = k.dot(theta)

# Make a classifier for one and two
mu1 = np.mean(train[:, :, 0], axis=1)
mu2 = np.mean(train[:, :, 1], axis=1)
S = (np.cov(train[:, :, 0]) + np.cov(train[:, :, 1])) / 2

t = test[:, 0, 1]
invS = np.linalg.inv(S + 0.000001 * np.identity(256))
p1 = mu1[None, :].dot(invS).dot(t) - mu1[None, :].dot(invS).dot(mu1)/2
p2 = mu2[None, :].dot(invS).dot(t) - mu2[None, :].dot(invS).dot(mu2)/2
print(np.sign(p1 - p2))

t = test[:, :, 1]
p1 = mu1[None, :].dot(invS).dot(t) - mu1[None, :].dot(invS).dot(mu1[:, None]) / 2
p2 = mu2[None, :].dot(invS).dot(t) - mu2[None, :].dot(invS).dot(mu2[:, None]) / 2
result = np.sign(p1 - p2)

print("The number of correct prediction: {}".format(np.sum(result == -1)))
print("The number of false prediction:   {}".format(np.sum(result != -1)))

print(np.where(result != -1)[1])

wrong1 = test[:, 68, 1]
plt.imshow(wrong1.reshape(16, 16), 'gray')

wrong2 = test[:, 179, 1]
plt.imshow(wrong2.reshape(16, 16), 'gray')



# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from scipy.io import loadmat
from tqdm import tqdm
from google.colab import drive
drive.mount('/content/drive')

# %cd /content/drive/My Drive/SML/

data = loadmat('digit.mat')
train = data['X']
test = data['T']

train = np.concatenate([train[:, :, 0], train[:, :, 1], train[:, :, 2], train[:, :, 3], train[:, :, 4],
                                train[:, :, 5], train[:, :, 6], train[:, :, 7], train[:, :, 8], train[:, :, 9]], 1)
h = 0.1

#tktバージョン
def kernel(x1, x2, h):
  return np.exp(-np.linalg.norm(x1-x2)/(2*h**2))

#カーネルマトリクスの計算
k = np.zeros([train.shape[1], train.shape[1]])
for i in tqdm(range(train.shape[1])):#可視化
  for j in range(train.shape[1]):
    k[i,j] = kernel(train[:,i], train[:,j], h)

def calc_design_matrix(x, c, h):     
  return np.exp(-(x[None] - c[:, None]) ** 2 / (2 * h ** 2)) 

K = calc_design_matrix(train[:,],train[:,],h)

print(np.linalg.norm(k-K))

train = np.concatenate([train[:, :, 0], train[:, :, 1], train[:, :, 2], train[:, :, 3], train[:, :, 4],
                                train[:, :, 5], train[:, :, 6], train[:, :, 7], train[:, :, 8], train[:, :, 9]], 1)
K = np.array([[kernel(train[:, i], train[:, j], h) for j in range(train.shape[1])] for i in tqdm(range(train.shape[1]))])

np.linalg.norm(k-K)